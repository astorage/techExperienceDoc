kafka

topic和日志
topic：分区日志（partition） offset，有顺序的，保留期限可以配置，而不管是否消费。
kafka的性能和数据大小无关，长时间存储数据没有问题。

消费者之间不影响

分布式

leader分区处理读写数据，follower只是同步leader的数据，在leader宕机的时候来后补leader。 负载均衡的。


生产者

topic，可以发送消息到指定的partion，也可以根据一定的算法实现partition的负载均衡


消费者 

group consumer。如果一个group中有多个消费者，partition会均衡的分配给group中消费者

消费者均衡的消费partion中的数据，均衡的工作由kafka动态的维护。

topic消费是没有顺序的，partition消费是有顺序的。要顺序消费topic的数据，可以用一个partition，以消费者实例。


保证

数据不丢失，数据写入和消费顺序


kafka作为消息系统

传统的消息系统  队列，发布订阅模式

消费者组中的消费者实例个数不能超过分区的数量 多余的消费者空闲。


kafka作为存储系统

消息中间件，可以作为消息的中间存储系统

kafka有数据备份，以便容错。而且会保证数据写入。

kafka使用磁盘结构，具有很好的扩展性。

可认为Kafka是一种高性能、低延迟、具备日志存储、备份和传播功能的分布式文件系统


kafka用作流处理

kafka stream可以做复杂的数据处理，然后输出到新的topic


设计

持久化
Kafka 对消息的存储和缓存严重依赖于文件系统

磁盘顺序读取写入，是磁盘的规律，操作系统使用预读，批量写。内存对磁盘的缓存，所有读写操作都是通过cache，pagecache

java，很消耗内存，堆中的数据增加，垃圾回收会很复杂也很慢。

使用pagecache，重启kafka，缓存依旧可用，如果使用程序缓存，需要重新构建缓存。pagecache和磁盘的数据一致性由操作系统维护，这样程序不用处理这方面的逻辑。


常量时间
持久化队列可以建立在简单的读取和向文件后追加两种操作之上，所有的操作复杂度都是O(1)，性能和数据大小完全分离开来


性能

大量的小型 I/O 操作，以及过多的字节拷贝


分组批量消息传送，分组批量读写磁盘，顺序读写，分担网络开销

字节拷贝，producer、broker、consumer使用相同的字节码格式

操作系统优化，  pagecache =》网络socket中， linux用sendfile， 这就是zero-copy


正常的流程有4次copy

1、磁盘 =》内核空间pagecache
2、内核空间pagecache =》用户空间缓存
3、用户空间缓存 =》 内核空间套接字缓存
4、内核套接字缓存 =》网络发送缓存


端到端批量压缩

压缩减少带宽，有利于远距离网络传输。批量压缩，压缩率更高。gzip、snappy、LZ4


The producer 

发送消息负载均衡，生产者客户端知道所有分区的信息，可以控制发送消息到哪一个分区，也可以实现负载均衡，比如hash

异步发送

批量发送，在内存中汇聚消息，并批量提交信息。可以配置批的大小，也可以配置特定的延迟时间。


消费者

消费者可以控制消费的partition，和offset




kafka 消费者采用pull，生产者采用push

kafka不需要记录每一条消息消费的多个状态，也不需要处理重复消费的问题，也不需要处理长期没收到确认的消息
它的策略是，只记录partition中将要消费数据的offset，仅仅是一个数字。消费者可以回退到以前的offset重复消费，这是一个很好的特性。



消息交付语义


producer consumer  语义保证

At most once——消息可能会丢失但绝不重传。
At least once——消息可以重传但绝不丢失。
Exactly once——这正是人们想要的, 每一条消息只被传递一次.

这个问题被分成了两部分：发布消息的持久性保证和消费消息的保证。


 producer 没有收到消息已经被提交的确认响应，会重传消息， 这里提供的是 at-least-once 的消息交付语义。kafka有幂等性传递保证，不会产生重复消息，每条消息都有一个序列号来避免重复。
 
 
 producer同时向多个topic 发送消息，有事务性的语义，可以保证消息发送到所有topic都成功或者都失败。这就是Kafka topic 之间的 exactly-once 的数据传递
 
 
 可以指定生产者需要的持久化级别
 
  producer 指定了它想要等待消息被提交，则可以使用10ms的量级。acks=all 或者 -1
  producer 也可以指定它想要完全异步地执行发送  acks=0
  producer它只想等待直到 leader 节点拥有该消息（follower 节点有没有无所谓）。acks=1
  
  
 consumer角度

 consumer先读取一批消息，保存消费的位置到log中，然后才进行消息处理。如果消费者在保存消费位置之后，处理消息之前挂掉了，新的消费者只会从保存的消费职位开始消费，这样会造成消息丢失。这就是at-most-once
 consumer先读取一批消息，然后处理消息，最后保存消费的位置到log中。如果消费者在处理消息之后，未保存消费位置之前崩溃，新的消费者接管，会重新消费已经处理过的消息。这就是at-least-once语义
 
 Kafka Streams
 topic=》topic  利用事务producer，在一个事务中，写两个topic，一个topic存储消费的位置，一个用来存储消费处理后的数据。事务成功，两个topic都成功，如果不成功，消费的位置恢复到原来的值，对于存储处理后消息的topic
 中的数据对其他消费者是否可见，得看事务隔离级别。 这就是exectly-once语义。
 
 外部系统的话 可以是用 two-phase commit；也可以将offset和处理后的数据合在一起保存，这样就可以保证offset和数据一起保存或者一起不保存（Kafka Connect）。
 
 Kafka 默认保证 at-least-once 的消息交付
 Kafka 允许用户通过禁用 producer 的重传功能和让 consumer 在处理一批消息之前提交 offset，来实现 at-most-once 的消息交付
 
 
 
 副本replication
 Kafka 允许 topic 的 partition 拥有若干副本，当集群中的节点出现故障时，能自动进行故障转移，保证数据的可用性。
 
 Kafka 默认使用备份机制，默认副本是1.
 
每个分区都有一个 leader 和零或多个 followers  
 总的副本数是包含 leader 的总和。
 所有的读写操作都由 leader 处理
 各分区的 leader 均 匀的分布在brokers 中
 所有的 followers 节点都同步 leader 节点的日志，日志中的消息和偏移量都和 leader 中的一致。
 Followers 节点就像普通的 consumer 那样从 leader 节点那里拉取消息并保存在自己的日志文件中。也可以批量拉取
 
 Kafka 判断节点是否存活有两种方式。
 1、节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接。
 2、果节点是个 follower ，它必须能及时的同步 leader 的写操作，并且延时不能太久。
 
 in sync 就是存活节点，如果有节点挂掉了, 或是写超时, 或是心跳超时, leader 就会把它从同步副本列表中移除。 同步超时和写超时的时间由 replica.lag.time.max.ms 配置确定。
 
 
 只有当消息被所有的副本节点加入到日志中时, 才算是提交, 只有提交的消息才会被 consumer 消费, 这样就不用担心一旦 leader 挂掉了消息会丢失。
 
 producer 也 可以选择是否等待消息被提交，这取决他们的设置在延迟时间和持久性之间的权衡，这个选项是由 producer 使用的 acks 设置控制
 
 Topic 可以设置同步备份的最小数量， producer 请求确认消息是否被写入到所有的备份时, 可以用最小同步数量判断。
 如果 producer 对同步的备份数没有严格的要求，即使同步的备份数量低于 最小同步数量（例如，仅仅只有 leader 同步了数据），消息也会被提交，然后被消费。
 Kafka 保证只要有至少一个同步中的节点存活，提交的消息就不会丢失。
 
 
 
 备份日志：Quorums, ISRs, 和状态机
 
 写入时候需要保证一定数量的副本写入成功，读取时需要保证读取一定数量的副本，读取和写入之间有重叠。这样的读写机制称为 Quorum。
 
 对提交决策和 leader 选举使用多数投票机制
 
 大多数投票方法有一个非常好的优点：延迟是取决于最快的服务器。副本数是3，则备份完成的等待时间取决于最快的 Follwer 。
 
 
 大多数投票的缺点是，多数的节点挂掉让你不能选择 leader。要冗余单点故障需要三份数据，并且要冗余两个故障需要五份的数据。
 
 quorum 算法更常用于共享集群配置（如 ZooKeeper ）， 而不适用于原始数据存储
 
Kafka 不是用大多数投票选择 leader

Kafka 动态维护了一个同步状态备份的集合ISR（a set of in-sync replicas），在这个集合中的节点都是和 leader 保持高度一致的，
只有这个集合的成员才 有资格被选举为 leader，一条消息必须被这个集合 所有 节点读取并追加到日志中了，这条消息才能视为提交。

 ISR 模型和 f+1 副本，一个 Kafka topic 冗余 f 个节点故障而不会丢失任何已经提交的消息

















































设计思想

动机

